{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole brain calcium imaging data from C. elegans, Kato et al. 2015\n",
    "\n",
    "Kato, S., Kaplan, H. S., Schrödel, T., Skora, S., Lindsay, T. H., Yemini, E., et al. (2015). Global Brain Dynamics Embed the Motor Command Sequence of Caenorhabditis elegans. Cell, 163(3), 656–669. http://doi.org/10.1016/j.cell.2015.09.034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVA_HisCl.mat       WT_NoStim.mat       WT_Stim.mat\n",
      "TestData.ipynb      WT_NoStim_pre73.mat readme_Kato2015.txt\n",
      "Contents of MAT file WT_Stim.mat: ['IDs', 'States', 'dataset', 'fps', 'stimulus', 'timeVectorSeconds', 'traces', 'tracesDif', 'traces_raw']\n",
      "\n",
      "========  loading fps 0\n",
      "3.0527777777777776\n",
      "\n",
      "========  loading dataset 0\n",
      "TS20140624b_lite-1_punc-31_NLS3_4eggs_56um_1mMTet_basalplusstim_720s\n",
      "\n",
      "========  loading timeVectorSeconds 0\n",
      "Data points (1, 2198): [0.00000000e+00 3.27570519e-01 6.55141037e-01 ... 7.19017288e+02\n",
      " 7.19344859e+02 7.19672429e+02]\n",
      "\n",
      "========  loading States 0\n",
      "Data points 2198: [4. 4. 4. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/padraig/anaconda/envs/py36/lib/python3.6/site-packages/hdmf/build/objectmapper.py:137: UserWarning: Value with data type float64 is being converted to data type float64 as specified.\n",
      "  % (g.name, s.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written NWB file to KatoEtAl2018.WT_Stim.0.nwb\n",
      "\n",
      "========  loading fps 1\n",
      "2.801388888888889\n",
      "\n",
      "========  loading dataset 1\n",
      "TS20140630h_lite-1_punc-31_NLS3_2eggs_56um_1mMTet_basalplusstim_720s\n",
      "\n",
      "========  loading timeVectorSeconds 1\n",
      "Data points (1, 2017): [0.00000000e+00 3.56965791e-01 7.13931582e-01 ... 7.18929103e+02\n",
      " 7.19286068e+02 7.19643034e+02]\n",
      "\n",
      "========  loading States 1\n",
      "Data points 2017: [1. 1. 1. ... 1. 1. 1.]\n",
      "Written NWB file to KatoEtAl2018.WT_Stim.1.nwb\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import pynwb\n",
    "import math\n",
    "from hdmf.backends.hdf5.h5_utils import H5DataIO\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "\n",
    "all_datarefs = ['WT_Stim']\n",
    "\n",
    "for data_ref in all_datarefs:\n",
    "    \n",
    "    mat_file = '%s.mat'%data_ref\n",
    "    h5_file = h5py.File(mat_file, 'r')\n",
    "    mat_contents = h5_file[data_ref]\n",
    "\n",
    "\n",
    "    print('Contents of MAT file %s: %s'%(mat_file, sorted(mat_contents.keys())))\n",
    "    \n",
    "    '''\n",
    "    From readme:\n",
    "    \n",
    "    traces_raw= neural activity traces uncorrected\n",
    "    traces = neural activity traces corrected for bleaching\n",
    "    tracesDif = derivative of traces\n",
    "    IDs = identified neuron IDs\n",
    "    timeVectorSeconds = time vector in seconds\n",
    "    fps = frames per second\n",
    "    dataset = name of dataset\n",
    "    stimulus\n",
    "        -identity = what was changed e.g. O2 (oxygen)\n",
    "        -type = stimulus type e.g. binary steps\n",
    "        -switchtimes =  time in seconds when stimulus changed from initial state to the other state\n",
    "        -initialstate = the state that the stimulus starts with, refers to \"conc\"\n",
    "        -conc = the concentrations of the stimulus\n",
    "        -concunits - units of the \"conc\"\n",
    "\n",
    "    States = vector of different state types (8 states for WT_NoStim, 4 states for WT_Stim and AVA_HisCl\n",
    "\n",
    "    8 states for WT_NoStim:\n",
    "        ‘FWD’ forward crawling; ‘SLOW’ forward slowing; ‘DT’ dorsal post reversal turn\n",
    "        ‘VT’ ventral post reversal turn; ‘REV1’ reverse crawling;\n",
    "        ‘REV2’ reverse crawling; ‘REVSUS’ sustained reverse crawling; ‘NOSTATE’ - ambiguous\n",
    "\n",
    "    4 states for WT_Stim and AVA_HisCl:\n",
    "        ‘FWD’ forward crawling; ‘REV’ reverse crawling\n",
    "        ‘REVSUS’ sustained reverse crawling; ‘TURN’ post reversal turn\n",
    "    '''\n",
    "    \n",
    "    for dataset_index in [0,1]:\n",
    "        \n",
    "        start_time = datetime.now(tz=tzlocal())\n",
    "        create_date = datetime.now(tz=tzlocal())\n",
    "\n",
    "        experimenter = '??? (Zimmer lab)'\n",
    "\n",
    "        main_ref = 'Kato et al. 2015 dataset taken from file %s.mat'%data_ref\n",
    "        nwbfile = pynwb.NWBFile(main_ref, \n",
    "                      main_ref, \n",
    "                      start_time,\n",
    "                      file_create_date=create_date,\n",
    "                      notes='NWB file created with pynwb v%s'%pynwb.__version__,\n",
    "                      experimenter=experimenter,\n",
    "                      experiment_description='ED...',\n",
    "                      institution='IN...')\n",
    "        \n",
    "        print('\\n========  loading fps %i'%dataset_index)\n",
    "        fps_raw_h5ref = np.array(mat_contents['fps'])\n",
    "        fps_raw = h5_file[fps_raw_h5ref[dataset_index][0]]\n",
    "        #print(fps_raw)\n",
    "        print(fps_raw[0][0])\n",
    "        \n",
    "\n",
    "        print('\\n========  loading dataset %i'%dataset_index)\n",
    "\n",
    "        raw_h5ref = np.array(mat_contents['dataset'])\n",
    "        raw = h5_file[raw_h5ref[dataset_index][0]]\n",
    "        #print(raw)\n",
    "        st = [r[0] for r in raw]\n",
    "        s2 = ''.join(map(chr,st))\n",
    "        print(s2)\n",
    "\n",
    "        print('\\n========  loading timeVectorSeconds %i'%dataset_index)\n",
    "\n",
    "        raw_h5ref = np.array(mat_contents['timeVectorSeconds'])\n",
    "        raw = h5_file[raw_h5ref[dataset_index][0]]\n",
    "        print('Data points %s: %s'%(raw.shape, raw[0]))\n",
    "        timestamps = raw[0]\n",
    "\n",
    "        print('\\n========  loading States %i'%dataset_index)\n",
    "\n",
    "        raw_h5ref = np.array(mat_contents['States'])\n",
    "        raw = h5_file[raw_h5ref[dataset_index][0]]\n",
    "        states = np.array([s[0] for s in raw])\n",
    "        print('Data points %s: %s'%(len(states), states))\n",
    "        \n",
    "        data = states\n",
    "\n",
    "        comments='Extracted from MAT file: %s.mat'%data_ref\n",
    "        wrapped_data = H5DataIO(data=data, compression=True) \n",
    "\n",
    "        ts_acq = pynwb.TimeSeries('States', wrapped_data, 'none', timestamps=timestamps,comments=comments,\n",
    "                                 description='vector of different state types')\n",
    "        nwbfile.add_acquisition(ts_acq)\n",
    "\n",
    "\n",
    "        nwb_file_name = 'KatoEtAl2018.%s.%i.nwb'%(data_ref, dataset_index)\n",
    "        io = pynwb.NWBHDF5IO(nwb_file_name, mode='w')\n",
    "        io.write(nwbfile)\n",
    "        io.close()\n",
    "        print(\"Written NWB file to %s\"%nwb_file_name)\n",
    "    \n",
    "    '''\n",
    "    key_set = sorted(mat_contents.keys())\n",
    "    traces_raw_h5ref = mat_contents['traces_raw']\n",
    "    traces_raw = h5_file[traces_raw_h5ref[0][0]]\n",
    "    print(traces_raw)\n",
    "    print(traces_raw.value)\n",
    "    print(traces_raw.value[0])\n",
    "    \n",
    "\n",
    "    print('IDs of cells: ')\n",
    "    IDs_h5ref = mat_contents['IDs']\n",
    "    IDs = h5_file[IDs_h5ref[0][0]]\n",
    "    print(IDs)\n",
    "    #print(IDs.value)\n",
    "    print(IDs[0])\n",
    "    print(h5_file[IDs[0][0]].value)\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    id = '???'\n",
    "    for i in range(15,25,1):\n",
    "        id = h5_file[IDs[i][0]].value[0]\n",
    "        print('ID: %s (%s)'%(id, type(id))) \n",
    "        if not type(id)==np.uint64:\n",
    "            id = [int(a) for a in h5_file[id[0]].value]\n",
    "            id = ''.join(chr(i) for i in id)\n",
    "        else:\n",
    "            id = '???'\n",
    "        print('Plotting cell %i: %s'%(i,id))\n",
    "        plt.plot(timeVectorSeconds.value[0],traces_raw.value[i], lw=.5, label='%i: %s'%(i,id))\n",
    "        plt.legend()\n",
    "\n",
    "        \n",
    "    plt.show()    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from dateutil.tz import tzlocal\n",
    "import pynwb\n",
    "import math\n",
    "from hdmf.backends.hdf5.h5_utils import H5DataIO\n",
    "\n",
    "print('Using pynwb v%s'%pynwb.__version__)\n",
    "'''\n",
    "for data_ref in all_datarefs:\n",
    "\n",
    "    mat_file = '%s.mat'%data_ref\n",
    "    mat_contents = sio.loadmat(mat_file)\n",
    "\n",
    "    start_time = datetime(2019, 1, 1, 11, tzinfo=tzlocal())\n",
    "    create_date = datetime.now(tz=tzlocal())\n",
    "\n",
    "    experimenter = 'Angelica da Silva Lantyer' if 'AL' in data_ref else \\\n",
    "                   ('Niccolò Calcini' if 'NC' in data_ref else \\\n",
    "                    ('Melanie Emmelkamp' if 'ME' in data_ref else '???'))\n",
    "\n",
    "    main_ref = 'Lantyer et al. dataset taken from file %s.mat'%data_ref\n",
    "    nwbfile = pynwb.NWBFile(main_ref, \n",
    "                      main_ref, \n",
    "                      start_time,\n",
    "                      file_create_date=create_date,\n",
    "                      notes='NWB file created with pynwb v%s'%pynwb.__version__,\n",
    "                      experimenter=experimenter,\n",
    "                      experiment_description='A databank for intracellular electrophysiological mapping of the adult somatosensory cortex',\n",
    "                      institution='Donders Institute for Brain, Cognition and Behaviour, Radboud University')\n",
    "\n",
    "\n",
    "    for t in mat_contents.keys():\n",
    "        if 'Trace_' in t:\n",
    "            print('Adding trace: %s'%t)\n",
    "            trace = mat_contents[t].T\n",
    "\n",
    "            #plt.plot(trace[0],trace[1], lw=.5, label='%s'%t)\n",
    "\n",
    "            timestamps = trace[0]\n",
    "            data = trace[1]\n",
    "\n",
    "            comments='Extracted from MAT file: %s.mat'%data_ref\n",
    "            \n",
    "            wrapped_data = H5DataIO(data=data, compression=True) \n",
    "            #wrapped_data = data \n",
    "\n",
    "            if t.endswith('_1'):\n",
    "                ts_stim = pynwb.TimeSeries('%s'%t, wrapped_data, 'A', timestamps=timestamps,comments=comments,\n",
    "                                          description='Membrane potential')\n",
    "                nwbfile.add_stimulus(ts_stim)\n",
    "            if t.endswith('_2'):\n",
    "                ts_acq = pynwb.TimeSeries('%s'%t, wrapped_data, 'V', timestamps=timestamps,comments=comments,\n",
    "                                         description='Applied current')\n",
    "                nwbfile.add_acquisition(ts_acq)\n",
    "\n",
    "\n",
    "    nwb_file_name = 'LantyerEtAl2018.%s.nwb'%(data_ref)\n",
    "    io = pynwb.NWBHDF5IO(nwb_file_name, mode='w')\n",
    "    io.write(nwbfile)\n",
    "    io.close()\n",
    "    print(\"Written NWB file to %s\"%nwb_file_name)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
